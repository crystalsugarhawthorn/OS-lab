# lab2 调试记录

## 预备工作

首先，根据指导书提示，先编译出带调试信息的QEMU：

```bash
# 进入QEMU源码目录
cd qemu-4.1.1

# 清理之前的编译结果
make distclean

# 重新配置，这次要带上调试选项
./configure --target-list=riscv32-softmmu,riscv64-softmmu --enable-debug

# 重新编译
make -j$(nproc)
```

随后修改Makefile，使用新的 QEMU 路径：

```Makefile
ifndef QEMU
QEMU := /home/OS/qemu-4.1.1/riscv64-softmmu/qemu-system-riscv64
endif
```

这样一来，我们就可以使用两个GDB进行调试了：
- GDB会话1：使用普通的gdb命令，附加到QEMU进程本身，用于调试QEMU的源码；
- GDB会话2：使用riscv64-unknown-elf-gdb，通过QEMU提供的调试接口连接，用于调试运行在模拟器中的ucore内核。

## 双GDB基本使用流程

首先，在终端1中启动QEMU，并启用GDB调试接口（这部分已由Makefile中的debug目标实现）：

```bash
make debug
```

然后，在终端2中启动GDB，附加到QEMU进程：

```bash
# 查找QEMU进程ID
pgrep -f qemu-system-riscv64

sudo gdb
(gdb) attach <QEMU_PID>
(gdb) handle SIGPIPE nostop noprint
(gdb) break get_physical_address # 设置断点 以物理地址转换函数为例
(gdb) continue
```

接着在终端3中启动另一个GDB会话，连接到QEMU的GDB服务器（这部分已由Makefile中的gdb目标实现）：

```bash
make gdb
(gdb) break kern_init # 可以在内核初始化函数处设置断点
(gdb) continue
(gdb) si # 单步执行
```

在终端3单步执行时，若触发了访存操作，终端2的GDB会在`get_physical_address`函数处停下，此时可以查看相关寄存器和内存状态，分析虚拟地址到物理地址的转换过程。还可以在终端2中利用`next`命令单步执行QEMU的源码，观察页表查找和TLB更新的具体实现。

另外，由于终端3中`si`命令是按照汇编指令单步执行的，因此可以精确控制内核代码在CPU中的执行流程，结合终端2中QEMU源码的调试，可以深入理解虚拟内存管理的实现细节。为了方便展示汇编指令，可以在终端3的GDB中使用以下命令：

```gdb
display /i $pc
```

这样，每次单步执行时，都会显示当前的汇编指令，便于理解内核代码的执行过程，更加直观地观察汇编指令与QEMU源码的对应情况。

## 调试过程

### 调试要求1：调试演示某个访存指令访问的虚拟地址是如何在qemu的模拟中被翻译成一个物理地址的

按照上面的双GDB调试流程，在本次调试中，我们通过双重 GDB 观察了 QEMU 对内核虚拟地址 `0xffffffffc0200054` 的翻译过程。这个过程由 QEMU 的取指操作触发，最终调用了 `get_physical_address` 函数。

#### 演示过程

1. 触发翻译：在 ucore (终端3) 中单步执行，当 QEMU 需要翻译一个新的代码块时，它会尝试从该代码块的起始虚拟地址（例如 `0xffffffffc0200054`）读取指令。
2. 进入翻译函数：这次读取操作因 TLB Miss 而调用了 `get_physical_address` 函数，QEMU 调试器 (终端2) 在此处中断。通过 `p/x addr` 命令，我们确认了正在被翻译的虚拟地址正是 `0xffffffffc0200054`。
3. 页表遍历：在终端2中，我们使用 `n` 命令单步执行 `get_physical_address` 的 C 源码。QEMU会进行下列操作：获取根页表、多级查询、计算PTE地址、读取PTE、解析PTE等。
4. 计算物理地址：当找到最终的叶子节点 PTE 后，函数将 PTE 中的物理页号（PPN）与虚拟地址中的页内偏移相结合，计算出最终的物理地址（`*physical = (ppn | (vpn & ...)) << PGSHIFT;`）。
5. 返回结果：函数将计算出的物理地址和访问权限 `prot` 通过指针返回给上层调用者（`riscv_cpu_get_phys_page_debug`），并返回 `TRANSLATE_SUCCESS`。
通过这个过程，我们完整地观察了一个虚拟地址是如何通过模拟硬件的页表遍历机制，一步步被 QEMU 翻译为物理地址的。

### 调试要求2：单步调试页表翻译的部分，解释关键的操作流程

页表翻译的核心在于 `get_physical_address` 函数中的 `for` 循环，它精确地模拟了硬件 MMU 的多级页表查询行为。

承接要求1，对 `get_physical_address` 函数的相关调试步骤如下：
```gdb
(gdb) c
Continuing.

Thread 1 "qemu-system-ris" hit Breakpoint 1, get_physical_address (env=0x6287fa880090, physical=0x7fff4a3a5718, prot=0x7fff4a3a5710, 
    addr=18446744072637907028, access_type=0, mmu_idx=1) at /home/OS/qemu-4.1.1/target/riscv/cpu_helper.c:158
158     {
(gdb) p/x addr
$2 = 0xffffffffc0200054
(gdb) p/x physical
$3 = 0x7fff4a3a5718
(gdb) n
163         int mode = mmu_idx;
(gdb) n
165         if (mode == PRV_M && access_type != MMU_INST_FETCH) {
(gdb) n
171         if (mode == PRV_M || !riscv_feature(env, RISCV_FEATURE_MMU)) {
(gdb) n
177         *prot = 0;
(gdb) n
181         int mxr = get_field(env->mstatus, MSTATUS_MXR);
(gdb) n
183         if (env->priv_ver >= PRIV_VERSION_1_10_0) {
(gdb) n
184             base = get_field(env->satp, SATP_PPN) << PGSHIFT;
(gdb) n
185             sum = get_field(env->mstatus, MSTATUS_SUM);
(gdb) n
186             vm = get_field(env->satp, SATP_MODE);
(gdb) n
187             switch (vm) {
(gdb) n
191               levels = 3; ptidxbits = 9; ptesize = 8; break;
(gdb) n
223         CPUState *cs = env_cpu(env);
(gdb) n
224         int va_bits = PGSHIFT + levels * ptidxbits;
(gdb) n
225         target_ulong mask = (1L << (TARGET_LONG_BITS - (va_bits - 1))) - 1;
(gdb) n
226         target_ulong masked_msbs = (addr >> (va_bits - 1)) & mask;
(gdb) n
227         if (masked_msbs != 0 && masked_msbs != mask) {
(gdb) n
231         int ptshift = (levels - 1) * ptidxbits;
(gdb) n
237         for (i = 0; i < levels; i++, ptshift -= ptidxbits) {
(gdb) n
238             target_ulong idx = (addr >> (PGSHIFT + ptshift)) &
(gdb) n
239                                ((1 << ptidxbits) - 1);
(gdb) n
238             target_ulong idx = (addr >> (PGSHIFT + ptshift)) &
(gdb) n
242             target_ulong pte_addr = base + idx * ptesize;
(gdb) n
244             if (riscv_feature(env, RISCV_FEATURE_PMP) &&
(gdb) n
245                 !pmp_hart_has_privs(env, pte_addr, sizeof(target_ulong),
(gdb) n
244             if (riscv_feature(env, RISCV_FEATURE_PMP) &&
(gdb) n
252             target_ulong pte = ldq_phys(cs->as, pte_addr);
(gdb) n
254             target_ulong ppn = pte >> PTE_PPN_SHIFT;
(gdb) n
256             if (!(pte & PTE_V)) {
(gdb) n
259             } else if (!(pte & (PTE_R | PTE_W | PTE_X))) {
(gdb) n
262             } else if ((pte & (PTE_R | PTE_W | PTE_X)) == PTE_W) {
(gdb) n
265             } else if ((pte & (PTE_R | PTE_W | PTE_X)) == (PTE_W | PTE_X)) {
(gdb) n
268             } else if ((pte & PTE_U) && ((mode != PRV_U) &&
(gdb) n
273             } else if (!(pte & PTE_U) && (mode != PRV_S)) {
(gdb) n
276             } else if (ppn & ((1ULL << ptshift) - 1)) {
(gdb) n
279             } else if (access_type == MMU_DATA_LOAD && !((pte & PTE_R) ||
(gdb) n
283             } else if (access_type == MMU_DATA_STORE && !(pte & PTE_W)) {
(gdb) n
286             } else if (access_type == MMU_INST_FETCH && !(pte & PTE_X)) {
(gdb) n
292                     (access_type == MMU_DATA_STORE ? PTE_D : 0);
(gdb) n
291                 target_ulong updated_pte = pte | PTE_A |
(gdb) n
295                 if (updated_pte != pte) {
(gdb) n
333                 target_ulong vpn = addr >> PGSHIFT;
(gdb) n
334                 *physical = (ppn | (vpn & ((1L << ptshift) - 1))) << PGSHIFT;
(gdb) n
337                 if ((pte & PTE_R) || ((pte & PTE_X) && mxr)) {
(gdb) n
338                     *prot |= PAGE_READ;
(gdb) n
340                 if ((pte & PTE_X)) {
(gdb) n
341                     *prot |= PAGE_EXEC;
(gdb) n
345                 if ((pte & PTE_W) &&
(gdb) n
346                         (access_type == MMU_DATA_STORE || (pte & PTE_D))) {
(gdb) n
347                     *prot |= PAGE_WRITE;
(gdb) n
349                 return TRANSLATE_SUCCESS;
(gdb) n
353     }
```

通过GDB输出，我们可以直观看到虚拟地址 `0xffffffffc0200054` 在 `get_physical_address` 函数中处理的关键操作流程：

1. 初始化 (L183-L231)：
   - 从 `satp` 寄存器确定页表模式（Sv39）和根页表的物理基地址 `base`。
   - 根据 Sv39 模式，设置查询层级 `levels = 3`，每级索引位宽 `ptidxbits = 9`。
   - `ptshift` 初始化为 `(3 - 1) * 9 = 18`，用于从虚拟地址中提取最高级的页表索引。
2. L2 页表查询 (循环第一次, i=0)：
    - `idx = (addr >> (12 + 18)) & 0x1FF`;：从虚拟地址 `addr` 的 `[38:30]` 位提取出 L2 页表的索引 `idx`。
    - `pte_addr = base + idx * 8;`：计算 L2 PTE 在物理内存中的地址。
    - `pte = ldq_phys(cs->as, pte_addr);`：读取 L2 PTE 的内容。
    - 若此 PTE 是一个有效的中间节点，代码会执行 `base = (pte >> 10) << 12;`，将 base 更新为 L1 页表的物理基地址。`ptshift` 减为 9。
3. L1 页表查询 (循环第二次, i=1)：
    - `idx = (addr >> (12 + 9)) & 0x1FF`;：从虚拟地址 `addr` 的 `[29:21]` 位提取出 L1 页表的索引 `idx`。
    - `pte_addr = base + idx * 8;`：计算 L1 PTE 的地址。
    - `pte = ldq_phys(cs->as, pte_addr);`：读取 L1 PTE。
    - 若此 PTE 仍为中间节点，再次更新 `base` 为 L0 页表的物理基地址。`ptshift` 减为 0。
4. L0 页表查询 (循环第三次, i=2)：
    - `idx = (addr >> (12 + 0)) & 0x1FF`;：从虚拟地址 `addr` 的 `[20:12]` 位提取出 L0 页表的索引 `idx`。
    - `pte_addr = base + idx * 8;`：计算 L0 PTE 的地址。
    - `pte = ldq_phys(cs->as, pte_addr);`：读取 L0 PTE。
    - 此时，该 PTE 应该是一个叶子节点（R/W/X 位不全为0）。代码进入 else 分支，进行权限检查。
5. 完成翻译 (L334)：
    - 权限检查通过后，执行 `*physical = (ppn | (vpn & ((1L << ptshift) - 1))) << PGSHIFT;`。此时 `ptshift` 为 0，该行代码等效于将 L0 PTE 中的物理页号（PPN）与虚拟地址中的页内偏移（addr 的低12位）组合，得到最终的4KB对齐的物理地址。
    - 设置 `prot` 权限位，函数成功返回。

从上述流程中也可以看出，TLB查询并不在 `get_physical_address` 函数中进行，而是在调用该函数之前的逻辑中处理的。理论上，当 TLB Miss 时，QEMU 才会调用此函数进行完整的页表遍历和地址翻译。

### 调试要求3：在qemu-4.1.1的源码中找到模拟cpu查找tlb的C代码，通过调试说明其中的细节

TLB相关源码主要位于`/qemu4.1.1/target/riscv/cpu_helper.c`和`qemu4.1.1/accel/tcg/cputlb.c`中。 在QEMU中，TLB的查找逻辑主要封装在`load_helper`和`store_helper`函数中，这两个函数分别处理加载和存储操作时的TLB查询。

主要的代码片段如下：

先判断TLB命中情况：
```c
    /* If the TLB entry is for a different page, reload and try again.  */
    if (!tlb_hit(tlb_addr, addr)) {
        if (!victim_tlb_hit(env, mmu_idx, index, tlb_off,
                            addr & TARGET_PAGE_MASK)) {
            tlb_fill(env_cpu(env), addr, size,
                     access_type, mmu_idx, retaddr);
            index = tlb_index(env, mmu_idx, addr);
            entry = tlb_entry(env, mmu_idx, addr);
        }
        tlb_addr = code_read ? entry->addr_code : entry->addr_read;
    }
```
如果主TLB未命中，QEMU并不会立即去执行完整的页表遍历 (tlb_fill)，而是会先查找一个二级缓存，即“受害者TLB”（Victim TLB）。如果在受害者TLB中找到了匹配项，它会把该条目与主TLB中对应的旧条目进行交换，从而实现一次快速的“救援”，并返回 true。

如果两级缓存都未命中，则调用 `tlb_fill` 函数，进入我们之前调试过的、缓慢的页表遍历流程。`tlb_fill` 函数会根据当前的页表结构，逐级查询页表，最终找到对应的物理地址，并将结果填充到TLB中，以便后续访问可以快速命中。
```c
bool riscv_cpu_tlb_fill(CPUState *cs, vaddr address, int size,
                        MMUAccessType access_type, int mmu_idx,
                        bool probe, uintptr_t retaddr)
{
    // ......
    ret = get_physical_address(env, &pa, &prot, address, access_type, mmu_idx);
    // ......
}
```

### 调试要求4：分析qemu中模拟出来的tlb与真实cpu中的tlb有什么逻辑上的区别

（*提示：可以尝试找一条未开启虚拟地址空间的访存语句进行调试，看看调用路径，和开启虚拟地址空间之后的访存语句对比*）

#### 场景一：虚拟地址空间未启用
首先，测试未开启虚拟地址空间的情况下`load_helper`的执行逻辑：
1. 在QEMU刚开始运行、处于OpenSBI阶段时，虚拟地址空间尚未启用。
2. 在此阶段，直接在终端2打断点于`load_helper`函数，并在终端3中执行`continue`。
3. 在终端2执行`continue`，程序会直接命中`load_helper`函数的断点。

观察此时中断的位置：
```gdb
(gdb) c
Continuing.
[Switching to Thread 0x7cce49fff6c0 (LWP 22816)]

Thread 2 "qemu-system-ris" hit Breakpoint 1.11, load_helper (full_load=0x5591835996c1 <full_le_ldul_cmmu>, code_read=true, 
    big_endian=false, size=4, retaddr=0, oi=35, addr=2147483718, env=0x5591baf7d090) at /home/OS/qemu-4.1.1/accel/tcg/cputlb.c:1252
1252        uintptr_t mmu_idx = get_mmuidx(oi);
(gdb) p/x addr
$1 = 0x80000046
```

此时的访存地址为`0x80000046`，这是一个物理地址，因为虚拟地址空间尚未启用。通过单步调试，得到如下结果：
```gdb
(gdb) c
Continuing.
[Switching to Thread 0x7ceb3ffff6c0 (LWP 31242)]

Thread 2 "qemu-system-ris" hit Breakpoint 1.11, load_helper (full_load=0x5b0156e7a6c1 <full_le_ldul_cmmu>, code_read=true, 
    big_endian=false, size=4, retaddr=0, oi=35, addr=2147483718, env=0x5b018ce66090) at /home/OS/qemu-4.1.1/accel/tcg/cputlb.c:1252
1252        uintptr_t mmu_idx = get_mmuidx(oi);
(gdb) p/x addr
$1 = 0x80000046
(gdb) n
1253        uintptr_t index = tlb_index(env, mmu_idx, addr);
(gdb) n
1254        CPUTLBEntry *entry = tlb_entry(env, mmu_idx, addr);
(gdb) n
1255        target_ulong tlb_addr = code_read ? entry->addr_code : entry->addr_read;
(gdb) n
1257            offsetof(CPUTLBEntry, addr_code) : offsetof(CPUTLBEntry, addr_read);
(gdb) n
1256        const size_t tlb_off = code_read ?
(gdb) n
1259            code_read ? MMU_INST_FETCH : MMU_DATA_LOAD;
(gdb) n
1258        const MMUAccessType access_type =
(gdb) n
1260        unsigned a_bits = get_alignment_bits(get_memop(oi));
(gdb) n
1265        if (addr & ((1 << a_bits) - 1)) {
(gdb) n
1271        if (!tlb_hit(tlb_addr, addr)) {
(gdb) s
tlb_hit (tlb_addr=2147483648, addr=2147483718) at /home/OS/qemu-4.1.1/include/exec/cpu-all.h:361
361         return tlb_hit_page(tlb_addr, addr & TARGET_PAGE_MASK);
(gdb) s
tlb_hit_page (tlb_addr=2147483648, addr=2147483648) at /home/OS/qemu-4.1.1/include/exec/cpu-all.h:350
350         return addr == (tlb_addr & (TARGET_PAGE_MASK | TLB_INVALID_MASK));
(gdb) s
351     }
(gdb) s
tlb_hit (tlb_addr=2147483648, addr=2147483718) at /home/OS/qemu-4.1.1/include/exec/cpu-all.h:362
362     }
(gdb) s
load_helper (full_load=0x5b0156e7a6c1 <full_le_ldul_cmmu>, code_read=true, big_endian=false, size=4, retaddr=0, oi=35, 
    addr=2147483718, env=0x5b018ce66090) at /home/OS/qemu-4.1.1/accel/tcg/cputlb.c:1283
1283        if (unlikely(tlb_addr & ~TARGET_PAGE_MASK)) {
(gdb) s
1314        if (size > 1
(gdb) n
1315            && unlikely((addr & ~TARGET_PAGE_MASK) + size - 1
(gdb) n
1337     do_aligned_access:
(gdb) nn
Undefined command: "nn".  Try "help".
(gdb) n
1338        haddr = (void *)((uintptr_t)addr + entry->addend);
(gdb) n
1339        switch (size) {
(gdb) n
1351            if (big_endian) {
(gdb) n
1354                res = (uint32_t)ldl_le_p(haddr);
(gdb) n
1356            break;
(gdb) n
1368        return res;
(gdb) n
full_le_ldul_cmmu (env=0x5b018ce66090, addr=2147483718, oi=35, retaddr=0) at /home/OS/qemu-4.1.1/accel/tcg/cputlb.c:1784
1784    }
```

我们可以对上述代码流程作简要分析：

在QEMU刚启动，CPU处于M-Mode执行OpenSBI代码时，分页未开启，所有内存访问都是物理地址访问。此时在`load_helper`函数处设置断点，单步调试一次取指操作（地址为`0x80000046`），我观察到如下执行路径：

1.  程序进入 `load_helper` 函数。
2.  计算TLB索引 `index`，获取TLB条目 `entry`。
3.  执行 `if (!tlb_hit(tlb_addr, addr))` 判断。由于是第一次访问该地址，TLB中没有缓存，`tlb_hit` 返回 `false`，条件成立。
4.  **关键步骤**：使用`step` 步入 `if` 块内部，程序**没有**调用 `tlb_fill` 去执行页表遍历，而是直接跳过了这个逻辑。
5.  程序继续执行，最终来到 `do_aligned_access` 标签处。
6.  执行 `haddr = (void *)((uintptr_t)addr + entry->addend);`。理论上，在分页未开启时，`entry->addend` 的值被设置为0，因此 `haddr` 就等于原始地址 `addr`。但经过测试，此时的`entry->addend == 0x760817e00000`，这可能是QEMU在初始化TLB条目时的特性。
7.  使用 `haddr` 从模拟的物理内存中读取数据。

#### 场景二：虚拟地址空间已启用
同样，我们可以在开启虚拟地址空间后，观察`load_helper`的执行逻辑：
1. 在ucore内核初始化完成后，虚拟地址空间被启用。
2. 在此阶段，同样在终端2打断点于`load_helper`函数，并在终端3中执行`continue`。
3. 在终端2执行`continue`，程序会直接命中`load_helper`函数的断点。观察此时中断的位置：

可见此时的访存地址为`0xffffffffc0200066`，这是一个虚拟地址，因为虚拟地址空间已启用。通过单步调试，得到如下结果：
```gdb
(gdb) c
Continuing.
[Switching to Thread 0x7c14d5b7d6c0 (LWP 41192)]

Thread 2 "qemu-system-ris" hit Breakpoint 1.11, load_helper (full_load=0x61d06c52a6c1 <full_le_ldul_cmmu>, code_read=true, 
    big_endian=false, size=4, retaddr=0, oi=33, addr=18446744072637907046, env=0x61d09ccbc090)
    at /home/OS/qemu-4.1.1/accel/tcg/cputlb.c:1252
1252        uintptr_t mmu_idx = get_mmuidx(oi);
(gdb) p/x addr
$1 = 0xffffffffc0200066
(gdb) n
1253        uintptr_t index = tlb_index(env, mmu_idx, addr);
(gdb) n
1254        CPUTLBEntry *entry = tlb_entry(env, mmu_idx, addr);
(gdb) n
1255        target_ulong tlb_addr = code_read ? entry->addr_code : entry->addr_read;
(gdb) n
1257            offsetof(CPUTLBEntry, addr_code) : offsetof(CPUTLBEntry, addr_read);
(gdb) n
1256        const size_t tlb_off = code_read ?
(gdb) n
1259            code_read ? MMU_INST_FETCH : MMU_DATA_LOAD;
(gdb) n
1258        const MMUAccessType access_type =
(gdb) n
1260        unsigned a_bits = get_alignment_bits(get_memop(oi));
(gdb) n
1265        if (addr & ((1 << a_bits) - 1)) {
(gdb) n
1271        if (!tlb_hit(tlb_addr, addr)) {
(gdb) n
1283        if (unlikely(tlb_addr & ~TARGET_PAGE_MASK)) {
(gdb) n
1314        if (size > 1
(gdb) n
1315            && unlikely((addr & ~TARGET_PAGE_MASK) + size - 1
(gdb) n
1337     do_aligned_access:
(gdb) n
1338        haddr = (void *)((uintptr_t)addr + entry->addend);
(gdb) n
1339        switch (size) {
(gdb) n
1351            if (big_endian) {
(gdb) n
1354                res = (uint32_t)ldl_le_p(haddr);
(gdb) n
1356            break;
(gdb) n
1368        return res;
(gdb) p entry->addend
$2 = 136429634060288
(gdb) p/x entry->addend
$3 = 0x7c14ffe00000
(gdb) p/x res
$4 = 0x45818e09
```

此时的执行路径与前面类似，但有一个关键区别：在执行 `haddr = (void *)((uintptr_t)addr + entry->addend);` 时，`entry->addend` 不再是`0x760817e00000`，而是一个更大的偏移值（`0x7c14ffe00000`）。这表明 `load_helper` 函数在虚拟地址空间启用后，TLB条目中的 `addend` 字段被正确设置为对应的物理地址偏移。通过这种方式，QEMU能够将虚拟地址 `0xffffffffc0200066` 映射到正确的物理地址，从而完成访存操作。

为方便查找真正调用`tlb_fill`的情况，更深刻地理解QEMU模拟`tlb`的功能，我们需要设置条件断点：
```gdb
(gdb) break load_helper
(gdb) break tlb_fill
(gdb) disable 2

(gdb) commands 1
Type commands for breakpoint(s) 1, one per line.
End with a line saying just "end".
> enable 2
> continue
> end

(gdb) commands 2
Type commands for breakpoint(s) 2, one per line.
End with a line saying just "end".
> disable 2
> end
```
程序会在 `load_helper` 处短暂暂停，启用 `tlb_fill` 断点后继续。如果 `load_helper` 内部真的调用了 `tlb_fill`，程序就会在 `tlb_fill` 的第一行正式停下来。如果 `load_helper` 执行完了都没有调用 `tlb_fill`，那么那个断点就相当于没起作用。

通过此方法，我们找到了一个访存地址确实触发了 `tlb_fill` 调用的情况，对应调用栈如下：

```gdb
(gdb) bt
#0  tlb_fill (cpu=0x5b018ce5d680, addr=18446744072637915648, size=1, access_type=MMU_DATA_LOAD, mmu_idx=1, retaddr=137349908400003)
    at /home/OS/qemu-4.1.1/accel/tcg/cputlb.c:871
#1  0x00005b0156e5f64a in load_helper (full_load=0x5b0156e5f414 <full_ldub_mmu>, code_read=false, big_endian=false, size=1, 
    retaddr=137349908400003, oi=1, addr=18446744072637915648, env=0x5b018ce66090) at /home/OS/qemu-4.1.1/accel/tcg/cputlb.c:1274
#2  full_ldub_mmu (env=0x5b018ce66090, addr=18446744072637915648, oi=1, retaddr=137349908400003)
    at /home/OS/qemu-4.1.1/accel/tcg/cputlb.c:1384
#3  0x00005b0156e5fafb in helper_ret_ldub_mmu (env=0x5b018ce66090, addr=18446744072637915648, oi=1, retaddr=137349908400003)
    at /home/OS/qemu-4.1.1/accel/tcg/cputlb.c:1391
#4  0x00007ceb44800942 in code_gen_buffer ()
#5  0x00005b0156e83199 in cpu_tb_exec (cpu=0x5b018ce5d680, itb=0x7ceb44800340 <code_gen_buffer+4883>)
    at /home/OS/qemu-4.1.1/accel/tcg/cpu-exec.c:173
#6  0x00005b0156e83fdf in cpu_loop_exec_tb (cpu=0x5b018ce5d680, tb=0x7ceb44800340 <code_gen_buffer+4883>, last_tb=0x7ceb3fffe988, 
    tb_exit=0x7ceb3fffe980) at /home/OS/qemu-4.1.1/accel/tcg/cpu-exec.c:621
#7  0x00005b0156e84305 in cpu_exec (cpu=0x5b018ce5d680) at /home/OS/qemu-4.1.1/accel/tcg/cpu-exec.c:732
#8  0x00005b0156e3653f in tcg_cpu_exec (cpu=0x5b018ce5d680) at /home/OS/qemu-4.1.1/cpus.c:1435
#9  0x00005b0156e36df8 in qemu_tcg_cpu_thread_fn (arg=0x5b018ce5d680) at /home/OS/qemu-4.1.1/cpus.c:1743
#10 0x00005b01572bcb5d in qemu_thread_start (args=0x5b018ce73d10) at util/qemu-thread-posix.c:502
#11 0x00007ceb4709caa4 in start_thread (arg=<optimized out>) at ./nptl/pthread_create.c:447
#12 0x00007ceb47129c6c in clone3 () at ../sysdeps/unix/sysv/linux/x86_64/clone3.S:78
```

虽然这种方式无法分析出`load_helper`内部的每一步细节，但至少确认了在虚拟地址空间启用后，`load_helper`确实会调用`tlb_fill`函数去处理TLB Miss的情况，从而触发页表遍历和地址翻译。

我们也可以重新检验在虚拟地址空间未启用时的情况，确认所有`load_helper`都没有调用`tlb_fill`，从而验证两种场景下TLB处理逻辑的区别。但经过测试，未启用虚拟地址空间时，`load_helper`也可能会调用`tlb_fill`，这可能是QEMU的某些特性或优化所致，这也是QEMU与真实硬件的一个逻辑区别。

#### 逻辑区别总结

通过对比上述两种场景的关键调用路径差异，我们简要总结了QEMU模拟TLB与真实CPU TLB的核心逻辑区别：

1.  **TLB的本质不同**：
    *   **真实CPU TLB**：是一块**硬件缓存**，它缓存的是**虚拟页号 (VPN) 到物理页号 (PPN) 的映射**。它的工作对软件完全透明，CPU硬件自动完成查询。
    *   **QEMU模拟TLB**：是一个**纯软件的数据结构**（C语言的`CPUTLBEntry`数组）。它缓存的不是简单的PPN，而是一个更直接的“地址加数”（addend）。这个 `addend` 经过精心计算，使得 `客户机虚拟地址 + addend` 能直接得到一个**宿主机内存的指针**。这是一种为了加速模拟而设计的软件技巧。

2.  **处理“实地址”模式的方式不同**：
    *   **真实CPU**：在分页关闭时，MMU和TLB整个单元都被旁路（Bypass），内存访问直接走物理总线，不存在“TLB查询”这个概念。
    *   **QEMU**：为了统一访存逻辑，**即使在分页关闭时，代码依然会执行TLB查询的路径**。它通过将 `addend` 设置为0，巧妙地实现了 `haddr = addr + 0`，即虚拟地址直接等于物理地址的效果。

3.  **TLB Miss的处理者不同**：
    *   **真实CPU**：TLB Miss由**硬件状态机**自动处理，它会发起一次内存访问来遍历页表。这个过程对正在执行的指令是“原子”的。
    *   **QEMU**：TLB Miss由**C语言函数 `tlb_fill`** 处理。这是一个软件执行的、相对缓慢的过程，我们可以通过GDB清晰地单步调试其中的每一步。


### 调试要求5：记录下你调试过程中比较有趣的细节，以及在观察模拟器通过软件模拟硬件执行的时候了解到的知识

在本次双重GDB调试中，我遇到了一个让我困惑的现象：

**现象：一条不访存的 `addi` 指令为何触发了地址翻译？**

调试过程中，我遇到了这样情况：
1.  在**终端3 (ucore GDB)** 中，我正使用 `si` 执行下一条指令。GDB显示该指令是 `addi a2, a2, 1092`，位于虚拟地址 `0xffffffffc0200060`。`addi` 是一条纯粹的算术运算指令，只操作寄存器，理论上绝不应该触发任何内存访问。
2.  然而，在我输入 `si` 的瞬间，**终端2 (QEMU GDB)** 的断点hit了，程序停在了 `get_physical_address` 函数内部，这明确表示正在进行地址翻译。

这似乎是一个矛盾：一条不访存的指令，为什么会导致QEMU去进行地址翻译？

**探究与发现：QEMU的翻译块（Translation Block）机制**

带着这个疑问，我检查了两个GDB的状态：
-   终端3 (ucore) 显示即将执行的指令地址是 `0xffffffffc0200060`。
-   终端2 (QEMU) 中，我通过 `p/x addr` 打印出正在被翻译的地址，结果是 `0xffffffffc0200054`。

很显然，这两个地址并不相同：QEMU并不是在为 `addi` 指令所在的地址 `0x...60` 进行翻译，而是在为它之前的地址 `0x...54` 进行翻译。为了搞清楚 `0x...54` 是什么，我在终端3中反汇编了它：
```gdb
(gdb) x/i 0xffffffffc0200054
   0xffffffffc0200054 <kern_init>:      auipc   a0,0x6
```

原来，这个地址是一条 `auipc` 指令，它是一个新代码块的开始。

结合这些线索，我询问了大模型，得到了关键的解释：

**QEMU的核心工作原理——基于翻译块（Translation Block, TB）的动态二进制翻译：**

1. **并非逐条解释：** 为了追求更好的性能，QEMU并不会像简单的模拟器那样逐条解释执行RISC-V指令。
2. **JIT编译：** QEMU更像一个即时编译器（JIT）。当模拟的CPU将要执行到一个新的代码区域时，QEMU会一次性读取一个“基本块”（一连串没有分支跳转的指令），然后将这整个RISC-V指令块翻译成一块等效的、能在宿主机（我的x86-64电脑）上直接运行的机器码。这个被翻译出来的原生代码块就是所谓的“翻译块（TB）”。
3. **缓存与复用：** QEMU会缓存这个TB。下次当ucore的PC指针再次指向这个基本块的入口时，QEMU就可以直接执行已经翻译好的、速度极快的原生x86-64代码，而无需再次翻译。

我们遇到的现象，正是这个翻译过程的体现。当我在终端3执行 `si` 后，ucore的PC指针落到了 `0xffffffffc0200054` 这个地址上。QEMU的执行引擎发现这个地址还没有对应的TB缓存，于是它必须暂停执行，开始翻译。

翻译的第一步，就是要从模拟内存中读取从 `0xffffffffc0200054` 开始的一系列RISC-V指令码。这个“为翻译而读取指令”的动作，本身就是一次取指（Instruction Fetch），自然需要进行地址翻译。正是这次取指操作，触发了TLB Miss，最终调用了 `get_physical_address`，命中了我在终端2的断点。

所以，地址翻译的发生，不是因为 addi 指令的执行，而是因为QEMU为了翻译一个包含了 addi 指令的代码块，而进行的预读取操作。这个发现让我深刻体会到，软件对硬件的模拟远非简单的指令循环，而是一个充满优化的、分层解耦的复杂系统。

### 调试要求6：记录实验过程中大模型的使用情况

在本次实验的调试过程中，我借助大语言模型（GitHub Copilot）解决了多个问题。以下是我与模型进行的几个典型对话：

#### 对话1：深入理解页表遍历的动机
**问题：**
> 既然已经有了QEMU的源码 `get_physical_address`，可以直接阅读来理解地址翻译过程，为什么还需要单步调试它？另外，QEMU的TLB缓存在哪里，为什么在这个函数里看不到？

**回答：**
> 模型的回答点明了静态分析与动态调试的核心区别：
> 1.  **动态过程**：源码是静态的，展示了所有可能性。而单步调试能让我看到在**特定输入**下，程序**实际**走了哪条路径，以及每一步变量（如`pte`, `base`）的具体值是如何变化的。
> 2.  **确认代码路径**：调试能帮我确认，对于我关心的这个操作，程序是否真的执行了我认为应该执行的那段代码。
> 3.  **TLB的位置**：模型解释了`get_physical_address`函数本身就是**页表遍历（Page Table Walk）**的实现，它是在**TLB Miss**之后才会被调用的慢速路径。QEMU的软件TLB位于更高层的代码中（如`load_helper`/`store_helper`），在访存指令被执行前，会先查找这个软件TLB。如果命中，则根本不会调用`get_physical_address`。

#### 对话2：探究`addi`指令触发地址翻译的深层原因
**问题：**
> 我在ucore中单步执行一条`addi`指令（纯算术运算，不访存），但却在QEMU的`get_physical_address`函数处触发了断点。这是为什么？

**回答：**
> 模型给出了一个非常深入的解释，并引入了**翻译块（Translation Block, TB）**的概念：
> 1.  **现象分析**：模型首先指出，我提供的两个GDB截图显示，ucore将要执行的指令地址和QEMU正在翻译的地址是**不同**的。
> 2.  **JIT编译机制**：模型解释说，QEMU为了性能，并非逐条解释执行指令，而是采用即时编译（JIT）技术。它会一次性读取一个基本块（basic block）的客户机指令，将其翻译成一块等效的、可在宿主机上直接运行的原生机器码，这个原生代码块就是“翻译块（TB）”。
> 3.  **根本原因**：我遇到的情况，是QEMU的执行引擎发现PC指向了一个尚未被翻译过的代码块入口。为了生成TB，QEMU必须先从模拟内存中**读取**这个代码块的指令码。正是这个**为翻译而进行的取指（Instruction Fetch）操作**，触发了TLB Miss和随后的地址翻译。

#### 对话3：修正调试思路，精确定位关键路径
**问题：**
> 我分别在虚拟地址开启前后调试了`load_helper`，但从GDB日志看，它们的调用路径似乎没什么区别，都没有调用`tlb_fill`。我的分析是不是错了？如何才能精确地只在`load_helper`内部调用`tlb_fill`时才中断？

**回答：**
> 模型指出了我调试手法上的一个关键失误，并给出了修正方案：
> 1.  **问题定位**：模型指出，我在`if (!tlb_hit(...))`这一行使用了`n` (next)命令，这会直接执行完整个`if`块，导致我错过了观察内部是否调用`tlb_fill`的机会。
> 2.  **解决方案1 (简单)**：建议我在`if`判断行改用`s` (step)命令。`s`会步入`if`块内部，如果`tlb_fill`被调用，GDB就会停在`tlb_fill`的第一行。
> 3.  **解决方案2 (精确)**：介绍了如何设置条件断点。即在`load_helper`的断点命令中启用一个预先设置但被禁用的`tlb_fill`断点，从而实现“只有从`load_helper`调用时才在`tlb_fill`中断”的精确控制。
