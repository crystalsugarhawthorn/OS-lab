# 用户进程

小组成员：
- 2310648 高景珩
- 2313892 章昊

---

## 实验目的

- 了解文件系统抽象层-VFS的设计与实现
- 了解基于索引节点组织方式的Simple FS文件系统与操作的设计与实现
- 了解“一切皆为文件”思想的设备文件设计
- 了解简单系统终端的实现

---

## 实验内容

### 练习1：完成读文件操作的实现（需要编码）

*首先了解打开文件的处理流程，然后参考本实验后续的文件读写操作的过程分析，填写在 kern/fs/sfs/sfs_inode.c中 的sfs_io_nolock()函数，实现读文件中数据的代码。*

`sfs_io_nolock` 函数是 Simple File System (SFS) 中执行底层文件读写操作的核心。它的目标是根据给定的偏移量 `offset` 和长度 `alenp`，将数据在用户提供的缓冲区 `buf` 和文件的磁盘块之间进行传输。为了高效地处理任意偏移和长度的读写，实现思路是将 I/O 操作分解为三个部分：

1.  **处理起始的非对齐部分**：如果 `offset` 不是块大小（`SFS_BLKSIZE`）的整数倍，那么第一次读写操作将从块内的 `offset % SFS_BLKSIZE` 位置开始，直到该块的末尾。
2.  **处理中间的对齐部分**：在处理完起始的非对齐数据后，后续的读写将是块对齐的。这部分可以循环地、以整块为单位进行高效的读写操作。
3.  **处理结尾的非对齐部分**：当所有完整的块都被处理后，如果还有剩余的数据没有达到请求的长度，就需要处理最后一个块内的部分数据。

在每个步骤中，都需要通过 `sfs_bmap_load_nolock` 函数将文件的逻辑块号映射到磁盘上的物理块号。对于写操作，如果写入位置超出了文件的当前末尾，该函数还会负责分配新的磁盘块。根据是读操作还是写操作，分别调用 `sfs_rbuf`/`sfs_rblock` 或 `sfs_wbuf`/`sfs_wblock` 来完成与磁盘的数据交换。

最终实现代码如下：

```c
static int
sfs_io_nolock(struct sfs_fs *sfs, struct sfs_inode *sin, void *buf, off_t offset, size_t *alenp, bool write) {
    struct sfs_disk_inode *din = sin->din;
    assert(din->type != SFS_TYPE_DIR);
    off_t endpos = offset + *alenp, blkoff;
    *alenp = 0;
	// calculate the Rd/Wr end position
    if (offset < 0 || offset >= SFS_MAX_FILE_SIZE || offset > endpos) {
        return -E_INVAL;
    }
    if (offset == endpos) {
        return 0;
    }
    if (endpos > SFS_MAX_FILE_SIZE) {
        endpos = SFS_MAX_FILE_SIZE;
    }
    if (!write) {
        if (offset >= din->size) {
            return 0;
        }
        if (endpos > din->size) {
            endpos = din->size;
        }
    }

    int (*sfs_buf_op)(struct sfs_fs *sfs, void *buf, size_t len, uint32_t blkno, off_t offset);
    int (*sfs_block_op)(struct sfs_fs *sfs, void *buf, uint32_t blkno, uint32_t nblks);
    if (write) {
        sfs_buf_op = sfs_wbuf, sfs_block_op = sfs_wblock;
    }
    else {
        sfs_buf_op = sfs_rbuf, sfs_block_op = sfs_rblock;
    }

    int ret = 0;
    size_t size, alen = 0;
    uint32_t ino;
    uint32_t blkno = offset / SFS_BLKSIZE;          // The NO. of Rd/Wr begin block
    uint32_t nblks = endpos / SFS_BLKSIZE - blkno;  // The size of Rd/Wr blocks

    // 分三段处理：前导非对齐（块内偏移）、中间整块、结尾非对齐（尾块部分）
    blkoff = offset % SFS_BLKSIZE;
    char *ptr = (char *)buf;

    // (1) 处理前导非对齐部分：从 offset 读/写到该块末尾或直接到 endpos（若只涉及一个块）
    if (blkoff != 0) {
        // 映射逻辑块号到物理块号，写入时可能需要在文件末尾分配新块
        if ((ret = sfs_bmap_load_nolock(sfs, sin, blkno, &ino)) != 0) {
            goto out;
        }
        // 若有后续整块则读满本块剩余字节，否则只读到 endpos
        size = (nblks != 0) ? (SFS_BLKSIZE - blkoff) : (endpos - offset);
        if ((ret = sfs_buf_op(sfs, ptr, size, ino, blkoff)) != 0) {
            goto out;
        }
        ptr += size;
        alen += size;
        blkno += 1;
        // 消耗了一个块的尾部，若原本存在整块区段则减少一个块计数
        if (nblks != 0) {
            nblks -= 1;
        }
    }

    // (2) 处理中间对齐的整块：一次一个块进行块级读/写
    while (nblks != 0) {
        if ((ret = sfs_bmap_load_nolock(sfs, sin, blkno, &ino)) != 0) {
            goto out;
        }
        if ((ret = sfs_block_op(sfs, ptr, ino, 1)) != 0) {
            goto out;
        }
        ptr += SFS_BLKSIZE;
        alen += SFS_BLKSIZE;
        blkno += 1;
        nblks -= 1;
    }

    // (3) 处理尾部非对齐部分：仅在仍有剩余字节时执行，避免与前导同块重复
    size_t remain = (size_t)(endpos - offset - alen);
    if (remain != 0) {
        // 此时应当处于块边界（或初始即对齐且未进入中间循环），尾部偏移为 0
        if ((ret = sfs_bmap_load_nolock(sfs, sin, blkno, &ino)) != 0) {
            goto out;
        }
        if ((ret = sfs_buf_op(sfs, ptr, remain, ino, 0)) != 0) {
            goto out;
        }
        alen += remain;
    }
    

out:
    *alenp = alen;
    if (offset + alen > sin->din->size) {
        sin->din->size = offset + alen;
        sin->dirty = 1;
    }
    return ret;
}
```

### 练习2：完成基于文件系统的执行程序机制的实现（需要编码）

*改写proc.c中的load_icode函数和其他相关函数，实现基于文件系统的执行程序机制。执行：make qemu。如果能看看到sh用户程序的执行界面，则基本成功了。如果在sh用户界面上可以执行`exit`, `hello`（更多用户程序放在user目录下）等其他放置在`sfs`文件系统中的其他执行程序，则可以认为本实验基本成功。*

为了实现从文件系统加载并执行程序，需要重写 `load_icode` 函数。旧的实现是直接从内存中的二进制数组加载程序，而新的实现需要通过文件描述符 `fd` 从 SFS 文件系统中读取 ELF 格式的可执行文件。

主要步骤如下：
1.  **创建新的内存管理结构**：为新程序创建一个独立的 `mm_struct` 和页目录表。
2.  **解析 ELF 文件**：通过 `load_icode_read` 函数（它封装了 `sysfile_seek` 和 `sysfile_read`）从文件描述符 `fd` 读取 ELF 头部和程序头表。
3.  **建立虚拟内存区域 (VMA)**：遍历程序头，对于每个类型为 `PT_LOAD` 的段（如代码段、数据段），调用 `mm_map` 创建一个对应的 VMA，并设置好 `VM_READ`, `VM_WRITE`, `VM_EXEC` 等权限。
4.  **分配物理内存并加载段内容**：与依赖缺页中断的按需加载不同，此实现采用**预先加载**的策略。它会立即为每个段的虚拟地址范围分配物理页面（`pgdir_alloc_page`），建立页表映射，然后再次调用 `load_icode_read` 将文件中的段内容精确地拷贝到新分配的物理页面中。对于 BSS 段，则通过 `memset` 清零。
5.  **创建用户栈**：为新程序创建一个 VMA 作为其用户栈，并预先分配物理页面。
6.  **设置用户环境**：将 `argc` 和 `argv` 等参数拷贝到用户栈顶。
7.  **更新进程状态**：将新的 `mm_struct` 和页目录表赋给当前进程，并刷新 TLB。
8.  **设置入口点**：最后，初始化中断帧（`trapframe`），设置好用户栈指针（`sp`）、程序入口地址（`epc`）以及传递给 `main` 函数的参数（`a0=argc`, `a1=argv`），以便在中断返回后能正确地从用户态开始执行新程序。

最终实现代码如下：

```c
// kern/process/proc.c
static int
load_icode(int fd, int argc, char **kargv)
{
    int ret = -E_NO_MEM;
    struct mm_struct *mm = NULL;
    struct elfhdr elf;

    // (1) 为当前进程创建新的 mm
    if ((mm = mm_create()) == NULL) {
        goto failed;
    }
    // (2) 创建新的页目录，并绑定到 mm
    if ((ret = setup_pgdir(mm)) != 0) {
        goto failed_destroy_mm;
    }

    // (3.1) 读取 ELF 头
    if ((ret = load_icode_read(fd, &elf, sizeof(struct elfhdr), 0)) != 0) {
        goto failed_pgdir;
    }
    if (elf.e_magic != ELF_MAGIC) {
        ret = -E_INVAL;
        goto failed_pgdir;
    }

    // (3.2) 遍历并加载每个可加载段（PT_LOAD）
    for (uint16_t i = 0; i < elf.e_phnum; i++) {
        struct proghdr ph;
        off_t phoff = elf.e_phoff + (off_t)i * sizeof(struct proghdr);
        if ((ret = load_icode_read(fd, &ph, sizeof(struct proghdr), phoff)) != 0) {
            goto failed_pgdir;
        }
        if (ph.p_type != ELF_PT_LOAD) {
            continue;
        }

        uintptr_t va = (uintptr_t)ph.p_va;
        size_t filesz = (size_t)ph.p_filesz;
        size_t memsz = (size_t)ph.p_memsz;
        off_t fileoff = (off_t)ph.p_offset;

        // (3.3) 建立 VMA（文本/数据段）
        uint32_t vm_flags = 0;
        if (ph.p_flags & ELF_PF_R) vm_flags |= VM_READ;
        if (ph.p_flags & ELF_PF_W) vm_flags |= VM_WRITE;
        if (ph.p_flags & ELF_PF_X) vm_flags |= VM_EXEC;
        if ((ret = mm_map(mm, va, memsz, vm_flags, NULL)) != 0) {
            goto failed_pgdir;
        }

        // (3.4) 为 TEXT/DATA 分配并填充页面；(3.5) 为 BSS 零填充
        uintptr_t la_start = ROUNDDOWN(va, PGSIZE);
        uintptr_t la_end = ROUNDUP(va + memsz, PGSIZE);

        // 页表项权限：用户位 + R/W/X 由段权限决定
        uint32_t perm = PTE_U;
        if (ph.p_flags & ELF_PF_R) perm |= PTE_R;
        if (ph.p_flags & ELF_PF_W) perm |= PTE_W;
        if (ph.p_flags & ELF_PF_X) perm |= PTE_X;

        for (uintptr_t la = la_start; la < la_end; la += PGSIZE) {
            struct Page *page = pgdir_alloc_page(mm->pgdir, la, perm);
            if (page == NULL) {
                ret = -E_NO_MEM;
                goto failed_pgdir;
            }
            void *kva = page2kva(page);
            memset(kva, 0, PGSIZE); // 预置为 0，用于 BSS
        }

        // 将文件内容拷入相应页（处理首页偏移）
        if (filesz != 0) {
            size_t copied = 0;
            while (copied < filesz) {
                uintptr_t la = ROUNDDOWN(va + copied, PGSIZE);
                size_t page_off = (va + copied) - la;
                size_t n = MIN(PGSIZE - page_off, filesz - copied);
                pte_t *ptep = get_pte(mm->pgdir, la, 0);
                assert(ptep != NULL && (*ptep & PTE_V));
                struct Page *page = pte2page(*ptep); // 通过 PTE 获取 Page
                void *dst = (char *)page2kva(page) + page_off;
                if ((ret = load_icode_read(fd, dst, n, fileoff + (off_t)copied)) != 0) {
                    goto failed_pgdir;
                }
                copied += n;
            }
        }
        // BSS 已在分配时用 memset 置零覆盖
    }

    // (4) 建立用户栈，并放置参数
    {
        uint32_t vm_flags = VM_READ | VM_WRITE | VM_STACK;
        uintptr_t ustack_base = USTACKTOP - USTACKSIZE;
        if ((ret = mm_map(mm, ustack_base, USTACKSIZE, vm_flags, NULL)) != 0) {
            goto failed_pgdir;
        }
        for (uintptr_t la = ustack_base; la < USTACKTOP; la += PGSIZE) {
            struct Page *page = pgdir_alloc_page(mm->pgdir, la, PTE_U | PTE_R | PTE_W);
            if (page == NULL) {
                ret = -E_NO_MEM;
                goto failed_pgdir;
            }
            memset(page2kva(page), 0, PGSIZE);
        }
    }

    // (5) 安装新的 mm 与页表，切换到用户地址空间
    mm_count_inc(mm);
    current->mm = mm;
    current->pgdir = PADDR(mm->pgdir);
    lsatp(current->pgdir);
    flush_tlb();

    // (6) 将 argc/argv 放入用户栈，并设置入口
    {
        uintptr_t sp = USTACKTOP;
        uintptr_t uargv[EXEC_MAX_ARG_NUM];

        // 逐个拷贝参数字符串（自顶向下），记录其用户地址
        for (int i = argc - 1; i >= 0; i--) {
            size_t len = strlen(kargv[i]) + 1;
            sp -= len;
            if (!copy_to_user(mm, (void *)sp, kargv[i], len)) {
                ret = -E_INVAL;
                goto failed_pgdir;
            }
            uargv[i] = sp;
        }
        // 对齐栈指针到 8 字节
        sp &= ~((uintptr_t)0x7);

        // 放置 argv 指针数组（最后一个为 NULL）
        sp -= (argc + 1) * sizeof(uintptr_t);
        for (int i = 0; i < argc; i++) {
            if (!copy_to_user(mm, (void *)(sp + i * sizeof(uintptr_t)), &uargv[i], sizeof(uintptr_t))) {
                ret = -E_INVAL;
                goto failed_pgdir;
            }
        }
        uintptr_t nullp = 0;
        if (!copy_to_user(mm, (void *)(sp + argc * sizeof(uintptr_t)), &nullp, sizeof(uintptr_t))) {
            ret = -E_INVAL;
            goto failed_pgdir;
        }

        // 设置用户态初始 Trapframe
        struct trapframe *tf = current->tf;
        memset(tf, 0, sizeof(*tf));
        tf->gpr.sp = sp;                 // 用户栈指针
        tf->gpr.a0 = argc;               // a0=argc
        tf->gpr.a1 = sp;                 // a1=argv 用户地址
        tf->epc = (uintptr_t)elf.e_entry; // 入口地址
        tf->status = (read_csr(sstatus) | SSTATUS_SPIE) & ~(SSTATUS_SPP | SSTATUS_SIE);
    }

    return 0;

failed_pgdir:
    exit_mmap(mm);
    put_pgdir(mm);
failed_destroy_mm:
    mm_destroy(mm);
failed:
    return ret;
}
```

完成上述改写后，重新编译内核并运行 `make qemu`，终端中结果如下：
```text
check_vma_struct() succeeded!
check_vmm() succeeded.
sched class: RR_scheduler
Initrd: 0xc0214010 - 0xc021bd0f, size: 0x00007d00
Initrd: 0xc021bd10 - 0xc029100f, size: 0x00075300
sfs: mount: 'simple file system' (106/11/117)
vfs: mount disk0.
++ setup timer interrupts
kernel_execve: pid = 2, name = "sh".
user sh is running!!!
I am the parent. Forking the child...
I am parent, fork a child pid 4
I am the parent, waiting now..
I am the child.
waitpid 4 ok.
exit pass.
I am the parent. Forking the child...
I am the parent. Running the child...
I am the child. spinning ...
I am the parent.  Killing the child...
kill returns 0
wait returns 0
spin may pass.
$ 
```

可见ucore正确加载并执行了`sfs`文件系统中的`sh`用户程序，并且能够正常运行了`exit`, `spin`等用户程序，说明基于文件系统的执行程序机制实现成功。

### 扩展练习 Challenge

#### 完成基于“UNIX的PIPE机制”的设计方案
[UNIX_PIPE](UNIX_PIPE.md)

#### 完成基于“UNIX的软连接和硬连接机制”的设计方案
[UNIX_LINK](UNIX_LINK.md)

---

## 知识点总结

本实验涵盖了操作系统中文件系统的核心知识点，主要包括以下几个方面：

操作系统引入文件系统的核心目的在于提供一种持久化存储数据的抽象机制，它将底层物理存储设备（如硬盘）的复杂、异构的块级访问接口，转化为用户易于理解和操作的、以“文件”和“目录”为单位的逻辑视图。

这一抽象过程的关键在于虚拟文件系统（VFS）的引入。VFS 作为内核中的一个中间层，定义了一套通用的文件模型，包括超级块（superblock）、索引节点（inode）、目录项（dentry）和文件对象（file）等核心数据结构。它通过统一的函数接口（如 `vop_open`, `vop_read`）屏蔽了不同具体文件系统（如本实验的 SFS、Linux 的 Ext4 或 Windows 的 NTFS）的实现差异，从而使得应用程序可以使用相同的系统调用（如 `open`, `read`）来无差别地访问不同介质、不同格式的文件系统，实现了“一切皆文件”的设计哲学。

本实验中的 Simple FS (SFS) 是该模型的一个具体实例，它在模拟的磁盘上实现了基于索引节点的数据块管理方式，通过磁盘索引节点（`sfs_disk_inode`）来记录文件的元数据和数据块指针，并通过目录项（`sfs_disk_entry`）来组织层次化的目录结构，完整地体现了从 VFS 抽象接口到底层文件系统具体实现的映射过程。
